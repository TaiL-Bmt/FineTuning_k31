{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-i5x7aO7yG2d"},"outputs":[],"source":["import os\n","\n","os.environ['KAGGLE_USERNAME'] = \"funnygame\" # username from the json file\n","os.environ['KAGGLE_KEY'] = \"34816227a9af12b6b988edafbf4d6f44\" # key from the json file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaNiwxx-q9CY"},"outputs":[],"source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7N3IxkdNzhXV"},"outputs":[],"source":["# Go to corresponding directory\n","%cd \"/content/gdrive/My Drive/Colab Notebooks/may_hoc_ung_dung\"\n","\n","# Clone repo - do 1 time\n","#!git clone https://github.com/TaiL-Bmt/FineTuning_k31.git\n","\n","# Pull update\n","%cd FineTuning_k31/\n","!git pull"]},{"cell_type":"code","source":["# Local colab setup\n","# Clone repo, should do only 1 time\n","#!git clone https://github.com/TaiL-Bmt/FineTuning_k31.git\n","\n","# Do an update, if any\n","%cd FineTuning_k31/\n","!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xIJR_wukoSnp","executionInfo":{"status":"ok","timestamp":1656592967619,"user_tz":-420,"elapsed":593,"user":{"displayName":"Funny Game","userId":"16440595761592407256"}},"outputId":"c2d7d65c-c7c5-4ed4-e72a-c8f2a397c806"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/FineTuning_k31\n","Already up to date.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OE8HccHzKVgV"},"outputs":[],"source":["# To investigate the VGG16 architecture\n","!python3 inspect_model.py -i -1"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ioWcJ8EvLaxW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656594021358,"user_tz":-420,"elapsed":606496,"user":{"displayName":"Funny Game","userId":"16440595761592407256"}},"outputId":"52467a79-4aa4-43ae-bfc6-28ede21dd4e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] loading images...\n","tcmalloc: large alloc 1433026560 bytes == 0x5d0a8000 @  0x7fd045e001e7 0x7fd042b520ce 0x7fd042bac726 0x7fd042c41841 0x59b076 0x515655 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fd0459fdc87 0x5b621a\n","[INFO] performing network surgery...\n","2022-06-30 12:50:27.788463: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] training model...\n","/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n","[INFO] training head...\n","finetune_flowers17.py:64: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  epochs = 25, steps_per_epoch = len(X_train)//32, verbose=1)\n","Epoch 1/25\n","9/9 [==============================] - ETA: 0s - loss: 10.7785 - accuracy: 0.09432022-06-30 12:50:42.043210: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 537686016 exceeds 10% of free system memory.\n","9/9 [==============================] - 17s 752ms/step - loss: 10.7785 - accuracy: 0.0943 - val_loss: 2.5901 - val_accuracy: 0.2811\n","Epoch 2/25\n","9/9 [==============================] - 5s 574ms/step - loss: 2.8335 - accuracy: 0.1774 - val_loss: 2.2981 - val_accuracy: 0.2945\n","Epoch 3/25\n","9/9 [==============================] - 5s 605ms/step - loss: 2.5069 - accuracy: 0.2679 - val_loss: 2.1125 - val_accuracy: 0.3595\n","Epoch 4/25\n","9/9 [==============================] - 5s 600ms/step - loss: 2.3840 - accuracy: 0.3160 - val_loss: 2.0362 - val_accuracy: 0.3438\n","Epoch 5/25\n","9/9 [==============================] - 5s 570ms/step - loss: 2.3180 - accuracy: 0.3321 - val_loss: 2.0815 - val_accuracy: 0.3527\n","Epoch 6/25\n","9/9 [==============================] - 5s 598ms/step - loss: 2.1796 - accuracy: 0.3611 - val_loss: 1.8103 - val_accuracy: 0.4782\n","Epoch 7/25\n","9/9 [==============================] - 5s 573ms/step - loss: 1.9983 - accuracy: 0.3962 - val_loss: 1.7266 - val_accuracy: 0.4546\n","Epoch 8/25\n","9/9 [==============================] - 5s 572ms/step - loss: 1.7043 - accuracy: 0.4604 - val_loss: 1.9927 - val_accuracy: 0.4166\n","Epoch 9/25\n","9/9 [==============================] - 5s 571ms/step - loss: 1.6701 - accuracy: 0.4943 - val_loss: 1.6816 - val_accuracy: 0.4983\n","Epoch 10/25\n","9/9 [==============================] - 5s 599ms/step - loss: 1.6511 - accuracy: 0.5019 - val_loss: 1.4060 - val_accuracy: 0.5677\n","Epoch 11/25\n","9/9 [==============================] - 5s 569ms/step - loss: 1.5825 - accuracy: 0.5170 - val_loss: 1.3384 - val_accuracy: 0.5689\n","Epoch 12/25\n","9/9 [==============================] - 5s 574ms/step - loss: 1.4487 - accuracy: 0.5358 - val_loss: 1.2485 - val_accuracy: 0.6193\n","Epoch 13/25\n","9/9 [==============================] - 5s 600ms/step - loss: 1.4990 - accuracy: 0.5623 - val_loss: 1.1870 - val_accuracy: 0.6260\n","Epoch 14/25\n","9/9 [==============================] - 5s 575ms/step - loss: 1.3154 - accuracy: 0.6113 - val_loss: 1.1901 - val_accuracy: 0.6461\n","Epoch 15/25\n","9/9 [==============================] - 5s 572ms/step - loss: 1.3510 - accuracy: 0.5698 - val_loss: 1.1461 - val_accuracy: 0.6361\n","Epoch 16/25\n","9/9 [==============================] - 5s 570ms/step - loss: 1.3007 - accuracy: 0.5774 - val_loss: 0.9752 - val_accuracy: 0.7055\n","Epoch 17/25\n","9/9 [==============================] - 5s 567ms/step - loss: 1.0405 - accuracy: 0.6415 - val_loss: 0.9411 - val_accuracy: 0.7133\n","Epoch 18/25\n","9/9 [==============================] - 5s 568ms/step - loss: 1.0906 - accuracy: 0.6755 - val_loss: 1.0039 - val_accuracy: 0.6842\n","Epoch 19/25\n","9/9 [==============================] - 5s 569ms/step - loss: 1.1164 - accuracy: 0.6189 - val_loss: 1.0035 - val_accuracy: 0.6865\n","Epoch 20/25\n","9/9 [==============================] - 5s 576ms/step - loss: 1.0249 - accuracy: 0.6566 - val_loss: 1.0057 - val_accuracy: 0.6932\n","Epoch 21/25\n","9/9 [==============================] - 5s 616ms/step - loss: 0.8779 - accuracy: 0.7222 - val_loss: 1.0160 - val_accuracy: 0.6898\n","Epoch 22/25\n","9/9 [==============================] - 5s 572ms/step - loss: 0.9843 - accuracy: 0.7057 - val_loss: 1.0138 - val_accuracy: 0.6965\n","Epoch 23/25\n","9/9 [==============================] - 5s 617ms/step - loss: 1.0636 - accuracy: 0.6566 - val_loss: 1.0950 - val_accuracy: 0.6585\n","Epoch 24/25\n","9/9 [==============================] - 5s 578ms/step - loss: 0.8049 - accuracy: 0.7094 - val_loss: 0.8995 - val_accuracy: 0.7368\n","Epoch 25/25\n","9/9 [==============================] - 5s 567ms/step - loss: 0.7688 - accuracy: 0.7547 - val_loss: 1.1945 - val_accuracy: 0.6484\n","[INFO] evaluating after initialization...\n","2022-06-30 12:52:56.099484: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 537686016 exceeds 10% of free system memory.\n","              precision    recall  f1-score   support\n","\n","    bluebell       0.60      0.84      0.70        55\n","   buttercup       0.69      0.67      0.68        52\n","  colts_foot       0.49      0.82      0.61        50\n","     cowslip       0.80      0.15      0.25        54\n","      crocus       0.76      0.41      0.53        54\n","    daffodil       0.70      0.67      0.69        52\n","       daisy       0.92      0.92      0.92        49\n","   dandelion       1.00      0.30      0.46        57\n","  fritillary       0.75      0.83      0.79        53\n","        iris       0.62      0.92      0.74        49\n"," lily_valley       1.00      0.35      0.52        51\n","       pansy       1.00      0.28      0.43        58\n","    snowdrop       0.58      0.74      0.65        47\n","   sunflower       0.93      0.93      0.93        55\n","   tigerlily       0.98      0.77      0.86        56\n","       tulip       0.30      0.65      0.41        48\n","  windflower       0.47      0.89      0.62        53\n","\n","    accuracy                           0.65       893\n","   macro avg       0.74      0.65      0.63       893\n","weighted avg       0.75      0.65      0.63       893\n","\n","[INFO] re-compiling model...\n","[INFO] fine-tuning model...\n","finetune_flowers17.py:82: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(aug.flow(X_train, y_train, batch_size=32), validation_data=(X_train, y_train), epochs=100, steps_per_epoch = len(X_train)//32, verbose=1)\n","Epoch 1/100\n","9/9 [==============================] - 5s 414ms/step - loss: 0.8106 - accuracy: 0.7358 - val_loss: 0.1389 - val_accuracy: 0.9865\n","Epoch 2/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.5811 - accuracy: 0.8189 - val_loss: 0.1017 - val_accuracy: 0.9865\n","Epoch 3/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.4657 - accuracy: 0.8528 - val_loss: 0.0912 - val_accuracy: 0.9899\n","Epoch 4/100\n","9/9 [==============================] - 4s 420ms/step - loss: 0.5090 - accuracy: 0.8299 - val_loss: 0.0744 - val_accuracy: 0.9933\n","Epoch 5/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.5614 - accuracy: 0.8113 - val_loss: 0.0747 - val_accuracy: 0.9966\n","Epoch 6/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.3587 - accuracy: 0.8981 - val_loss: 0.0622 - val_accuracy: 0.9933\n","Epoch 7/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.5218 - accuracy: 0.8226 - val_loss: 0.0621 - val_accuracy: 0.9966\n","Epoch 8/100\n","9/9 [==============================] - 3s 386ms/step - loss: 0.4140 - accuracy: 0.8679 - val_loss: 0.0561 - val_accuracy: 0.9966\n","Epoch 9/100\n","9/9 [==============================] - 4s 419ms/step - loss: 0.3619 - accuracy: 0.8958 - val_loss: 0.0490 - val_accuracy: 0.9966\n","Epoch 10/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.3522 - accuracy: 0.8906 - val_loss: 0.0441 - val_accuracy: 0.9966\n","Epoch 11/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.4333 - accuracy: 0.8604 - val_loss: 0.0459 - val_accuracy: 0.9966\n","Epoch 12/100\n","9/9 [==============================] - 3s 390ms/step - loss: 0.3211 - accuracy: 0.8830 - val_loss: 0.0428 - val_accuracy: 0.9933\n","Epoch 13/100\n","9/9 [==============================] - 4s 420ms/step - loss: 0.3906 - accuracy: 0.8681 - val_loss: 0.0413 - val_accuracy: 0.9966\n","Epoch 14/100\n","9/9 [==============================] - 3s 419ms/step - loss: 0.3646 - accuracy: 0.8830 - val_loss: 0.0364 - val_accuracy: 0.9966\n","Epoch 15/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.2624 - accuracy: 0.9170 - val_loss: 0.0338 - val_accuracy: 0.9966\n","Epoch 16/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.4041 - accuracy: 0.8679 - val_loss: 0.0312 - val_accuracy: 0.9966\n","Epoch 17/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.3827 - accuracy: 0.8792 - val_loss: 0.0327 - val_accuracy: 0.9966\n","Epoch 18/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2672 - accuracy: 0.9396 - val_loss: 0.0297 - val_accuracy: 0.9966\n","Epoch 19/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.3864 - accuracy: 0.8755 - val_loss: 0.0322 - val_accuracy: 0.9966\n","Epoch 20/100\n","9/9 [==============================] - 3s 387ms/step - loss: 0.3354 - accuracy: 0.8943 - val_loss: 0.0301 - val_accuracy: 0.9933\n","Epoch 21/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.3372 - accuracy: 0.8981 - val_loss: 0.0310 - val_accuracy: 0.9933\n","Epoch 22/100\n","9/9 [==============================] - 4s 396ms/step - loss: 0.3306 - accuracy: 0.8943 - val_loss: 0.0249 - val_accuracy: 1.0000\n","Epoch 23/100\n","9/9 [==============================] - 4s 395ms/step - loss: 0.2768 - accuracy: 0.8981 - val_loss: 0.0249 - val_accuracy: 1.0000\n","Epoch 24/100\n","9/9 [==============================] - 4s 395ms/step - loss: 0.2826 - accuracy: 0.9170 - val_loss: 0.0216 - val_accuracy: 1.0000\n","Epoch 25/100\n","9/9 [==============================] - 4s 419ms/step - loss: 0.3161 - accuracy: 0.8958 - val_loss: 0.0204 - val_accuracy: 1.0000\n","Epoch 26/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2792 - accuracy: 0.9170 - val_loss: 0.0221 - val_accuracy: 1.0000\n","Epoch 27/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2468 - accuracy: 0.9245 - val_loss: 0.0209 - val_accuracy: 1.0000\n","Epoch 28/100\n","9/9 [==============================] - 3s 421ms/step - loss: 0.2893 - accuracy: 0.9019 - val_loss: 0.0192 - val_accuracy: 1.0000\n","Epoch 29/100\n","9/9 [==============================] - 4s 419ms/step - loss: 0.2588 - accuracy: 0.9062 - val_loss: 0.0175 - val_accuracy: 1.0000\n","Epoch 30/100\n","9/9 [==============================] - 4s 389ms/step - loss: 0.2518 - accuracy: 0.9245 - val_loss: 0.0164 - val_accuracy: 1.0000\n","Epoch 31/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2892 - accuracy: 0.9132 - val_loss: 0.0170 - val_accuracy: 1.0000\n","Epoch 32/100\n","9/9 [==============================] - 3s 387ms/step - loss: 0.2496 - accuracy: 0.9170 - val_loss: 0.0164 - val_accuracy: 1.0000\n","Epoch 33/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.2085 - accuracy: 0.9396 - val_loss: 0.0163 - val_accuracy: 1.0000\n","Epoch 34/100\n","9/9 [==============================] - 4s 417ms/step - loss: 0.2739 - accuracy: 0.9167 - val_loss: 0.0142 - val_accuracy: 1.0000\n","Epoch 35/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.3050 - accuracy: 0.9094 - val_loss: 0.0143 - val_accuracy: 1.0000\n","Epoch 36/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2517 - accuracy: 0.9132 - val_loss: 0.0163 - val_accuracy: 1.0000\n","Epoch 37/100\n","9/9 [==============================] - 3s 390ms/step - loss: 0.3575 - accuracy: 0.8943 - val_loss: 0.0167 - val_accuracy: 1.0000\n","Epoch 38/100\n","9/9 [==============================] - 4s 421ms/step - loss: 0.2483 - accuracy: 0.9132 - val_loss: 0.0150 - val_accuracy: 1.0000\n","Epoch 39/100\n","9/9 [==============================] - 4s 416ms/step - loss: 0.2769 - accuracy: 0.9201 - val_loss: 0.0139 - val_accuracy: 1.0000\n","Epoch 40/100\n","9/9 [==============================] - 4s 452ms/step - loss: 0.2340 - accuracy: 0.9208 - val_loss: 0.0151 - val_accuracy: 1.0000\n","Epoch 41/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.2312 - accuracy: 0.9132 - val_loss: 0.0129 - val_accuracy: 1.0000\n","Epoch 42/100\n","9/9 [==============================] - 4s 422ms/step - loss: 0.2669 - accuracy: 0.9028 - val_loss: 0.0126 - val_accuracy: 0.9966\n","Epoch 43/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.2905 - accuracy: 0.9132 - val_loss: 0.0132 - val_accuracy: 0.9966\n","Epoch 44/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2157 - accuracy: 0.9245 - val_loss: 0.0103 - val_accuracy: 1.0000\n","Epoch 45/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.2169 - accuracy: 0.9283 - val_loss: 0.0110 - val_accuracy: 1.0000\n","Epoch 46/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.2045 - accuracy: 0.9321 - val_loss: 0.0105 - val_accuracy: 1.0000\n","Epoch 47/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.2325 - accuracy: 0.9245 - val_loss: 0.0135 - val_accuracy: 1.0000\n","Epoch 48/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.2246 - accuracy: 0.9434 - val_loss: 0.0103 - val_accuracy: 1.0000\n","Epoch 49/100\n","9/9 [==============================] - 3s 385ms/step - loss: 0.2874 - accuracy: 0.9245 - val_loss: 0.0148 - val_accuracy: 1.0000\n","Epoch 50/100\n","9/9 [==============================] - 3s 389ms/step - loss: 0.2444 - accuracy: 0.9094 - val_loss: 0.0121 - val_accuracy: 1.0000\n","Epoch 51/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2546 - accuracy: 0.9170 - val_loss: 0.0099 - val_accuracy: 1.0000\n","Epoch 52/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.2472 - accuracy: 0.9208 - val_loss: 0.0114 - val_accuracy: 1.0000\n","Epoch 53/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2517 - accuracy: 0.9132 - val_loss: 0.0096 - val_accuracy: 1.0000\n","Epoch 54/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.2481 - accuracy: 0.9132 - val_loss: 0.0107 - val_accuracy: 1.0000\n","Epoch 55/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.1924 - accuracy: 0.9358 - val_loss: 0.0089 - val_accuracy: 1.0000\n","Epoch 56/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.1869 - accuracy: 0.9434 - val_loss: 0.0086 - val_accuracy: 1.0000\n","Epoch 57/100\n","9/9 [==============================] - 4s 419ms/step - loss: 0.1676 - accuracy: 0.9410 - val_loss: 0.0077 - val_accuracy: 1.0000\n","Epoch 58/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2362 - accuracy: 0.9283 - val_loss: 0.0097 - val_accuracy: 0.9966\n","Epoch 59/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2536 - accuracy: 0.9283 - val_loss: 0.0076 - val_accuracy: 1.0000\n","Epoch 60/100\n","9/9 [==============================] - 4s 395ms/step - loss: 0.2045 - accuracy: 0.9283 - val_loss: 0.0087 - val_accuracy: 1.0000\n","Epoch 61/100\n","9/9 [==============================] - 4s 424ms/step - loss: 0.2046 - accuracy: 0.9271 - val_loss: 0.0072 - val_accuracy: 1.0000\n","Epoch 62/100\n","9/9 [==============================] - 4s 398ms/step - loss: 0.1969 - accuracy: 0.9358 - val_loss: 0.0069 - val_accuracy: 1.0000\n","Epoch 63/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2289 - accuracy: 0.9170 - val_loss: 0.0071 - val_accuracy: 1.0000\n","Epoch 64/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.2193 - accuracy: 0.9321 - val_loss: 0.0143 - val_accuracy: 0.9966\n","Epoch 65/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.2896 - accuracy: 0.9019 - val_loss: 0.0071 - val_accuracy: 1.0000\n","Epoch 66/100\n","9/9 [==============================] - 3s 388ms/step - loss: 0.1749 - accuracy: 0.9509 - val_loss: 0.0058 - val_accuracy: 1.0000\n","Epoch 67/100\n","9/9 [==============================] - 4s 417ms/step - loss: 0.2436 - accuracy: 0.9236 - val_loss: 0.0066 - val_accuracy: 1.0000\n","Epoch 68/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.1898 - accuracy: 0.9434 - val_loss: 0.0070 - val_accuracy: 1.0000\n","Epoch 69/100\n","9/9 [==============================] - 4s 418ms/step - loss: 0.1977 - accuracy: 0.9340 - val_loss: 0.0058 - val_accuracy: 1.0000\n","Epoch 70/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.1963 - accuracy: 0.9434 - val_loss: 0.0056 - val_accuracy: 1.0000\n","Epoch 71/100\n","9/9 [==============================] - 3s 390ms/step - loss: 0.1987 - accuracy: 0.9321 - val_loss: 0.0057 - val_accuracy: 1.0000\n","Epoch 72/100\n","9/9 [==============================] - 3s 386ms/step - loss: 0.1774 - accuracy: 0.9358 - val_loss: 0.0054 - val_accuracy: 1.0000\n","Epoch 73/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.1631 - accuracy: 0.9434 - val_loss: 0.0061 - val_accuracy: 1.0000\n","Epoch 74/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.2310 - accuracy: 0.9132 - val_loss: 0.0055 - val_accuracy: 1.0000\n","Epoch 75/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.1857 - accuracy: 0.9472 - val_loss: 0.0057 - val_accuracy: 1.0000\n","Epoch 76/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.2248 - accuracy: 0.9094 - val_loss: 0.0062 - val_accuracy: 1.0000\n","Epoch 77/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.2090 - accuracy: 0.9321 - val_loss: 0.0057 - val_accuracy: 1.0000\n","Epoch 78/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.1492 - accuracy: 0.9547 - val_loss: 0.0053 - val_accuracy: 1.0000\n","Epoch 79/100\n","9/9 [==============================] - 4s 396ms/step - loss: 0.1890 - accuracy: 0.9434 - val_loss: 0.0056 - val_accuracy: 1.0000\n","Epoch 80/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.1665 - accuracy: 0.9472 - val_loss: 0.0051 - val_accuracy: 1.0000\n","Epoch 81/100\n","9/9 [==============================] - 4s 416ms/step - loss: 0.1715 - accuracy: 0.9444 - val_loss: 0.0043 - val_accuracy: 1.0000\n","Epoch 82/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.2299 - accuracy: 0.9283 - val_loss: 0.0041 - val_accuracy: 1.0000\n","Epoch 83/100\n","9/9 [==============================] - 4s 455ms/step - loss: 0.1562 - accuracy: 0.9434 - val_loss: 0.0043 - val_accuracy: 1.0000\n","Epoch 84/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.1964 - accuracy: 0.9396 - val_loss: 0.0041 - val_accuracy: 1.0000\n","Epoch 85/100\n","9/9 [==============================] - 4s 424ms/step - loss: 0.2402 - accuracy: 0.9170 - val_loss: 0.0048 - val_accuracy: 1.0000\n","Epoch 86/100\n","9/9 [==============================] - 4s 394ms/step - loss: 0.1808 - accuracy: 0.9509 - val_loss: 0.0042 - val_accuracy: 1.0000\n","Epoch 87/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.1600 - accuracy: 0.9434 - val_loss: 0.0035 - val_accuracy: 1.0000\n","Epoch 88/100\n","9/9 [==============================] - 3s 383ms/step - loss: 0.1621 - accuracy: 0.9396 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 89/100\n","9/9 [==============================] - 4s 418ms/step - loss: 0.1655 - accuracy: 0.9444 - val_loss: 0.0037 - val_accuracy: 1.0000\n","Epoch 90/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.1854 - accuracy: 0.9472 - val_loss: 0.0035 - val_accuracy: 1.0000\n","Epoch 91/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.1415 - accuracy: 0.9547 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 92/100\n","9/9 [==============================] - 3s 390ms/step - loss: 0.1687 - accuracy: 0.9660 - val_loss: 0.0036 - val_accuracy: 1.0000\n","Epoch 93/100\n","9/9 [==============================] - 4s 393ms/step - loss: 0.1545 - accuracy: 0.9547 - val_loss: 0.0038 - val_accuracy: 1.0000\n","Epoch 94/100\n","9/9 [==============================] - 4s 390ms/step - loss: 0.1850 - accuracy: 0.9434 - val_loss: 0.0036 - val_accuracy: 1.0000\n","Epoch 95/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.1832 - accuracy: 0.9547 - val_loss: 0.0031 - val_accuracy: 1.0000\n","Epoch 96/100\n","9/9 [==============================] - 4s 422ms/step - loss: 0.1354 - accuracy: 0.9583 - val_loss: 0.0025 - val_accuracy: 1.0000\n","Epoch 97/100\n","9/9 [==============================] - 4s 428ms/step - loss: 0.1264 - accuracy: 0.9736 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 98/100\n","9/9 [==============================] - 4s 426ms/step - loss: 0.2016 - accuracy: 0.9321 - val_loss: 0.0028 - val_accuracy: 1.0000\n","Epoch 99/100\n","9/9 [==============================] - 4s 391ms/step - loss: 0.1738 - accuracy: 0.9396 - val_loss: 0.0027 - val_accuracy: 1.0000\n","Epoch 100/100\n","9/9 [==============================] - 4s 392ms/step - loss: 0.1956 - accuracy: 0.9321 - val_loss: 0.0039 - val_accuracy: 1.0000\n","[INFO] evaluating after fine-tuning...\n","2022-06-30 13:00:14.763634: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 537686016 exceeds 10% of free system memory.\n","              precision    recall  f1-score   support\n","\n","    bluebell       0.94      0.62      0.75        55\n","   buttercup       0.86      0.81      0.83        52\n","  colts_foot       0.67      0.82      0.74        50\n","     cowslip       0.83      0.63      0.72        54\n","      crocus       0.73      0.80      0.76        54\n","    daffodil       0.78      0.73      0.75        52\n","       daisy       0.98      0.96      0.97        49\n","   dandelion       1.00      0.65      0.79        57\n","  fritillary       0.90      0.87      0.88        53\n","        iris       0.87      0.92      0.89        49\n"," lily_valley       0.84      0.82      0.83        51\n","       pansy       0.98      0.81      0.89        58\n","    snowdrop       0.70      0.83      0.76        47\n","   sunflower       1.00      0.91      0.95        55\n","   tigerlily       0.89      0.89      0.89        56\n","       tulip       0.39      0.77      0.51        48\n","  windflower       0.89      0.91      0.90        53\n","\n","    accuracy                           0.81       893\n","   macro avg       0.84      0.81      0.81       893\n","weighted avg       0.84      0.81      0.81       893\n","\n","[INFO] serializing model...\n","2022-06-30 13:00:18.246582: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"]}],"source":["# To perform network surgery and fine-tune VGG16 on the Flowers-17 dataset\n","!python3 finetune_flowers17.py -d ./flower17 -m flowers17.model\n"]}],"metadata":{"colab":{"name":"FineTuning_chap5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPcT1T1CSmmSpbMtmiO+r7I"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}